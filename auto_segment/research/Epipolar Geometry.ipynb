{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epipolar Geometry implementation from https://docs.opencv.org/3.2.0/da/de9/tutorial_py_epipolar_geometry.html.\n",
    "\n",
    "Our hope is to see if we can just use together superpixels that are overlapping with epipolars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'SIFT'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5245686e203d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/myleft.jpg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#queryimage # left image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/myright.jpg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#trainimage # right image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msift\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIFT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# find the keypoints and descriptors with SIFT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mkp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdes1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msift\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'SIFT'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "\n",
    "# Checks if a matrix is a valid rotation matrix.\n",
    "def isRotationMatrix(R):\n",
    "    Rt = np.transpose(R)\n",
    "    shouldBeIdentity = np.dot(Rt, R)\n",
    "    I = np.identity(3, dtype=R.dtype)\n",
    "    n = np.linalg.norm(I - shouldBeIdentity)\n",
    "    return n < 1e-6\n",
    "\n",
    "\n",
    "# Calculates rotation matrix to euler angles\n",
    "# The result is the same as MATLAB except the order\n",
    "# of the euler angles ( x and z are swapped ).\n",
    "def rotationMatrixToEulerAngles(R):\n",
    "    assert (isRotationMatrix(R))\n",
    "\n",
    "    sy = math.sqrt(R[0, 0] * R[0, 0] + R[1, 0] * R[1, 0])\n",
    "\n",
    "    singular = sy < 1e-6\n",
    "\n",
    "    if not singular:\n",
    "        x = math.atan2(R[2, 1], R[2, 2])\n",
    "        y = math.atan2(-R[2, 0], sy)\n",
    "        z = math.atan2(R[1, 0], R[0, 0])\n",
    "    else:\n",
    "        x = math.atan2(-R[1, 2], R[1, 1])\n",
    "        y = math.atan2(-R[2, 0], sy)\n",
    "        z = 0\n",
    "\n",
    "    return np.array([x, y, z])\n",
    "\n",
    "\n",
    "def drawlines(img1,img2,lines,pts1,pts2):\n",
    "    ''' img1 - image on which we draw the epilines for the points in img2\n",
    "        lines - corresponding epilines '''\n",
    "    r = img1.shape[0]\n",
    "    c = img1.shape[1]\n",
    "    #img1 = cv2.cvtColor(img1,cv2.COLOR_GRAY2BGR)\n",
    "    #img2 = cv2.cvtColor(img2,cv2.COLOR_GRAY2BGR)\n",
    "    for r,pt1,pt2 in zip(lines,pts1,pts2):\n",
    "        color = tuple(np.random.randint(0,255,3).tolist())\n",
    "        x0,y0 = map(int, [0, -r[2]/r[1] ])\n",
    "        x1,y1 = map(int, [c, -(r[2]+r[0]*c)/r[1] ])\n",
    "        img1 = cv2.line(img1, (x0,y0), (x1,y1), color,3)\n",
    "        img1 = cv2.circle(img1,tuple(pt1[0]),5,color,-1)\n",
    "        img2 = cv2.circle(img2,tuple(pt2[0]),5,color,-1)\n",
    "    return img1,img2\n",
    "\n",
    "def match_features(img1, img2, intrinsics, dist):\n",
    "    w = img1.shape[1]\n",
    "    h = img1.shape[0]\n",
    "    # Initiate ORB detector\n",
    "    orb = cv2.ORB_create(scoreType=cv2.ORB_FAST_SCORE, nfeatures=1000)\n",
    "    # find the keypoints with ORB\n",
    "    kp1 = orb.detect(img1, None)\n",
    "    kp2 = orb.detect(img2, None)\n",
    "    # compute the descriptors with ORB\n",
    "    kp1, des1 = orb.compute(img1, kp1)\n",
    "    #print('kp1: ', kp1[0].pt)\n",
    "    #print('des1:', des1)\n",
    "    kp2, des2 = orb.compute(img2, kp2)\n",
    "    # draw only keypoints location,not size and orientation\n",
    "    vis = cv2.drawKeypoints(img1, kp1, None, color=(0, 255, 0), flags=0)\n",
    "    #plt.imshow(vis), plt.show()\n",
    "\n",
    "    # create BFMatcher object\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "    # Match descriptors.\n",
    "    matches = bf.match(des1, des2)\n",
    "\n",
    "    # Sort them in the order of their distance.\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "    img3 = np.zeros_like(img2)\n",
    "    # Draw first 10 matches.\n",
    "    n_matches = 100\n",
    "    img3 = cv2.drawMatches(img1, kp1, img2, kp2, matches[:n_matches], img3, flags=2)\n",
    "    #plt.imshow(img3), plt.show()\n",
    "\n",
    "    #findBaselineTriangulation\n",
    "    pleft = np.eye(3,4)\n",
    "    pright = np.eye(3,4)\n",
    "\n",
    "    focal = intrinsics[0,0]\n",
    "    ppx = intrinsics[0,2]\n",
    "    ppy = intrinsics[1,2]\n",
    "    alignedLeft = {'pt': [], 'des': []}\n",
    "    alignedRight = {'pt': [], 'des': []}\n",
    "    leftBackReference = []\n",
    "    rightBackReference = []\n",
    "    #Arrange matching points in aligned arrays:\n",
    "    for i, match in enumerate(matches[:n_matches]):\n",
    "        qid = match.queryIdx\n",
    "        tid = match.trainIdx\n",
    "        alignedLeft['pt'].append(kp1[qid].pt)\n",
    "        alignedLeft['des'].append(des1[qid,:])\n",
    "        alignedRight['pt'].append(kp2[tid].pt)\n",
    "        alignedRight['des'].append(des2[tid,:])\n",
    "    pts1 = np.array(alignedLeft['pt']).reshape(n_matches, 1, -1).astype(np.float32)\n",
    "    pts2 = np.array(alignedRight['pt']).reshape(n_matches, 1, -1).astype(np.float32)\n",
    "\n",
    "\n",
    "    #plt.subplot(221), plt.scatter(pts1[:,0,0], pts1[:,0,1]), plt.title('pts1'),  plt.xlim(0, w), plt.ylim(0, h), plt.gca().invert_yaxis()\n",
    "    #plt.subplot(222), plt.scatter(pts2[:,0,0], pts2[:,0,1]), plt.title('pts2'),  plt.xlim(0, w), plt.ylim(0, h), plt.gca().invert_yaxis()\n",
    "    #plt.subplot(223), plt.imshow(img1, 'gray'), plt.title('img1')\n",
    "    #plt.subplot(224), plt.imshow(img2, 'gray'), plt.title('img2')\n",
    "    #plt.show()\n",
    "\n",
    "    '''\n",
    "    pts_uv1 = cv2.undistortPoints(pts1, intrinsics, distCoeffs=None, P=intrinsics)\n",
    "    pts_uv2 = cv2.undistortPoints(pts2, intrinsics, distCoeffs=None, P=intrinsics)\n",
    "\n",
    "    for pt in pts_uv1[:,0,:]:\n",
    "        cv2.circle(img1, (pt[0], pt[1]), 10, (255), -1)\n",
    "    for pt in pts_uv2[:,0,:]:\n",
    "        cv2.circle(img2, (pt[0], pt[1]), 10, (255), -1)\n",
    "\n",
    "\n",
    "    plt.subplot(221), plt.scatter(pts_uv1[:,0,0], pts_uv1[:,0,1]), plt.title('pts1'),  plt.xlim(0, w), plt.ylim(0, h), plt.gca().invert_yaxis()\n",
    "    plt.subplot(222), plt.scatter(pts_uv2[:,0,0], pts_uv2[:,0,1]), plt.title('pts2'),  plt.xlim(0, w), plt.ylim(0, h), plt.gca().invert_yaxis()\n",
    "    plt.subplot(223), plt.imshow(img1, 'gray'), plt.title('img1')\n",
    "    plt.subplot(224), plt.imshow(img2, 'gray'), plt.title('img2')\n",
    "    #plt.show()\n",
    "\n",
    "    pts_uv1_t = np.reshape(pts_uv1, (1,-1,2))[0,0:4,:]\n",
    "    pts_uv2_t = np.reshape(pts_uv2, (1,-1,2))[0,0:4,:]\n",
    "    print('pts_uv1_t:', pts_uv1_t, pts_uv1_t.dtype)\n",
    "    print('pts_uv2_t:', pts_uv2_t, pts_uv2_t.dtype)\n",
    "\n",
    "    pts_uv1_t = np.reshape(pts1, (1,-1,2))[0,0:4,:]\n",
    "    pts_uv2_t = np.reshape(pts2, (1,-1,2))[0,0:4,:]\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(pts_uv1_t, pts_uv2_t)\n",
    "\n",
    "    print('M: ', M)\n",
    "\n",
    "    imt = cv2.imread('chess.jpg')\n",
    "\n",
    "    #M = np.eye(3)\n",
    "    dst = cv2.warpPerspective(imt, M, (imt.shape[1], imt.shape[0]))\n",
    "    #print(dst)\n",
    "\n",
    "    plt.subplot(121), plt.imshow(img1, 'gray'), plt.title('Input')\n",
    "    plt.subplot(122), plt.imshow(dst), plt.title('Output')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    retval, mask = cv2.findHomography(pts1, pts2)\n",
    "    print(retval, mask)\n",
    "    M = cv2.estimateRigidTransform(pts1, pts2, True)\n",
    "    print(M)\n",
    "\n",
    "    dst = cv2.warpAffine(img1, M, (img1.shape[1], img1.shape[0]))\n",
    "    #print(dst)\n",
    "\n",
    "    plt.subplot(131), plt.imshow(img1), plt.title('img1')\n",
    "    plt.subplot(132), plt.imshow(img2), plt.title('img2')\n",
    "    plt.subplot(133), plt.imshow(dst), plt.title('img1 warped')\n",
    "    plt.show()\n",
    "\n",
    "    exit(0)\n",
    "\n",
    "    '''\n",
    "\n",
    "    F, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_LMEDS)\n",
    "    # We select only inlier points\n",
    "    pts1 = pts1[mask.ravel() == 1]\n",
    "    pts2 = pts2[mask.ravel() == 1]\n",
    "\n",
    "    print('F: ', F)\n",
    "\n",
    "    # Find epilines corresponding to points in right image (second image) and\n",
    "    # drawing its lines on left image\n",
    "    lines1 = cv2.computeCorrespondEpilines(pts2.reshape(-1, 1, 2), 2, F)\n",
    "    lines1 = lines1.reshape(-1, 3)\n",
    "    img5, img6 = drawlines(img1, img2, lines1, pts1, pts2)\n",
    "    # Find epilines corresponding to points in left image (first image) and\n",
    "    # drawing its lines on right image\n",
    "    lines2 = cv2.computeCorrespondEpilines(pts1.reshape(-1, 1, 2), 1, F)\n",
    "    lines2 = lines2.reshape(-1, 3)\n",
    "    img3, img4 = drawlines(img2, img1, lines2, pts2, pts1)\n",
    "    plt.subplot(121), plt.imshow(img5)\n",
    "    plt.subplot(122), plt.imshow(img3)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    E, mask = cv2.findEssentialMat(pts1, pts2, focal=focal, pp=(ppx, ppy))\n",
    "    print('E: ', E)\n",
    "    points, R, t, mask = cv2.recoverPose(E, pts1, pts2, focal=focal, pp=(ppx, ppy), mask=mask)\n",
    "    # print('points: ', points)\n",
    "    print('R: ', R)\n",
    "    print('t: ', t)\n",
    "    # print('mask: ', mask)\n",
    "    M_r = np.hstack((R, t))\n",
    "    M_l = np.hstack((np.eye(3, 3), np.zeros((3, 1))))\n",
    "\n",
    "\n",
    "    print(M_r, M_r.shape)\n",
    "\n",
    "    print('angles:',rotationMatrixToEulerAngles(R))\n",
    "\n",
    "    exit(0)\n",
    "    \n",
    "    #triangulate:\n",
    "\n",
    "    P_l = np.dot(intrinsics, M_l)\n",
    "    P_r = np.dot(intrinsics, M_r)\n",
    "    point_4d_hom = cv2.triangulatePoints(M_l, M_r, pts1, pts2)\n",
    "    print('point_4d_hom: ', point_4d_hom)\n",
    "    point_4d = point_4d_hom / np.tile(point_4d_hom[-1, :], (4, 1))\n",
    "    point_3d = point_4d[:3, :].T\n",
    "\n",
    "    print(point_3d)\n",
    "\n",
    "    from matplotlib import pyplot\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    import random\n",
    "\n",
    "\n",
    "    fig = pyplot.figure()\n",
    "    ax = Axes3D(fig)\n",
    "\n",
    "    sequence_containing_x_vals = point_3d[:,0]\n",
    "    sequence_containing_y_vals = point_3d[:,1]\n",
    "    sequence_containing_z_vals = point_3d[:,2]\n",
    "\n",
    "    ax.scatter(sequence_containing_x_vals, sequence_containing_y_vals, sequence_containing_z_vals)\n",
    "    pyplot.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calibrate():\n",
    "    # termination criteria\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "    rows = 7\n",
    "    cols = 7\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((cols * rows, 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:cols, 0:rows].T.reshape(-1, 2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = []  # 3d point in real world space\n",
    "    imgpoints = []  # 2d points in image plane.\n",
    "\n",
    "    import pylab\n",
    "    import imageio\n",
    "    #filename = 'calib/checkerboard.mp4'\n",
    "    #vid = imageio.get_reader(filename,  'ffmpeg')\n",
    "    images = []\n",
    "    #for i in range(10):\n",
    "    #  image = vid.get_data(i)\n",
    "    #  images.append(image)\n",
    "    #  #cv2.imwrite('calib/frame_' + str(i) + '.jpg', image)\n",
    "    import glob\n",
    "\n",
    "    #for i in range(0, len(images), 1):\n",
    "    #images = ['IMG_20171211_151001.jpg']\n",
    "    images = glob.glob('calib/*.jpg')\n",
    "    print(images)\n",
    "    for fname in images:\n",
    "        img = cv2.imread(fname)\n",
    "        img = cv2.resize(img, None, fx=0.2, fy=0.2, interpolation=cv2.INTER_CUBIC)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        #cv2.imshow('img', gray)\n",
    "        #cv2.waitKey(500)\n",
    "\n",
    "        print('Processing calibration images')\n",
    "        # Find the chess board corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (cols, rows), None)\n",
    "        print(ret)\n",
    "        # If found, add object points, image points (after refining them)\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "\n",
    "            corners2 = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n",
    "            imgpoints.append(corners2)\n",
    "\n",
    "            # Draw and display the corners\n",
    "            img = cv2.drawChessboardCorners(img, (cols, rows), corners2, ret)\n",
    "            #cv2.imshow('img', img)\n",
    "            #cv2.waitKey(500)\n",
    "\n",
    "    if len(images) == 0:\n",
    "        print(\"Put images into calib directory.\")\n",
    "    return  cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "def from_video():\n",
    "    import pylab\n",
    "    import imageio\n",
    "    filename = 'toothpick.mp4'\n",
    "    vid = imageio.get_reader(filename,  'ffmpeg')\n",
    "    images = []\n",
    "    for i in range(210): #350\n",
    "      image = vid.get_data(i)\n",
    "      images.append(image)\n",
    "\n",
    "    imgL = cv2.cvtColor(images[0], cv2.COLOR_BGR2GRAY)#cv2.imread('tsukuba_l.png',0)\n",
    "    imgR = cv2.cvtColor(images[150], cv2.COLOR_BGR2GRAY)#cv2.imread('tsukuba_r.png',0)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(imgL, 'gray')\n",
    "    plt.figure()\n",
    "    plt.imshow(imgR, 'gray')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs = calibrate()\n",
    "print('Intrinsic Matrix: ', mtx)\n",
    "\n",
    "\n",
    "imgL = cv2.imread('im1.jpg')\n",
    "imgR = cv2.imread('im2.jpg')\n",
    "\n",
    "imgL = cv2.cvtColor(imgL, cv2.COLOR_BGR2RGB)\n",
    "imgR = cv2.cvtColor(imgR, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "match_features(imgL, imgR, mtx, dist)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "exit(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "img = cv2.imread('../calib/IMG_20171211_151001.jpg')\n",
    "img = cv2.resize(img, None, fx=0.2, fy=0.2, interpolation=cv2.INTER_CUBIC)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "h,  w = img.shape[:2]\n",
    "newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx,dist,(w,h),1,(w,h))\n",
    "\n",
    "# undistort\n",
    "mapx,mapy = cv2.initUndistortRectifyMap(mtx,dist,None,newcameramtx,(w,h),5)\n",
    "dst = cv2.remap(gray,mapx,mapy,cv2.INTER_LINEAR)\n",
    "\n",
    "# crop the image\n",
    "x,y,w,h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "cv2.imwrite('calibresult.png',dst)\n",
    "plt.figure()\n",
    "plt.imshow(dst, 'gray')\n",
    "plt.show()\n",
    "\n",
    "imgL = cv2.cvtColor(cv2.imread('im1.png'), cv2.COLOR_BGR2GRAY)\n",
    "imgR = cv2.cvtColor(cv2.imread('im2.png'), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "imgL = cv2.remap(imgL,mapx,mapy,cv2.INTER_LINEAR)\n",
    "imgR = cv2.remap(imgR,mapx,mapy,cv2.INTER_LINEAR)\n",
    "\n",
    "\n",
    "stereo = cv2.StereoBM_create(numDisparities=16, blockSize=15)\n",
    "disparity = stereo.compute(imgL,imgR)\n",
    "plt.figure()\n",
    "plt.imshow(disparity,'gray')\n",
    "print(disparity)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
